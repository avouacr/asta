---
title: "module6"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{module6}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r setup}
library(asta)
library(skimr)
library(tidymodels)
```



# menuItem 1 : Classification supervisée

## menuSubItem : données

Choisir la base de données et le pourcentage de test :

En affichage : 
le skim du train (fichier d'entraînement)
le skim du test (fichier test)

En variable globale, on a les bases de données train et test qui seront 
transmises aux sous-modules suivants.

```{r}
#paramètres
part_training <- 3/4 #proportion du découpage aléatoire en training et test
var_strata <- "quality" #variable de stratification : souvent la variable target
# nb_folds <-10 #nombre de classes pour la validation croisée

set.seed(123)
#Découpage en training et en test
data_split <- rsample::initial_split(vins, 
                                     strata = .data[[var_strata]],
                                     prop = part_training)

train_data <- training(data_split) #le fichier d'entraînement
test_data <- testing(data_split) #le fichier de test
skim(train_data)
skim(test_data)
```



## menuSubItem : preparation de la base

On part du fichier d'entraînement qui est une variable globale du module précédent.

### Modifs de la base d'entraînement

Une fenêtre avec la modif de la base de données : 
A la fin du module de préparation, la base de données a été modifiée : 
- selection des variables rentrant dans le modèle
- centrage-réduction d'une sélection de variables numériques
- pour transformer des variables nominales en indicatrices
- pour mettre certaines variables au carré ou en interaction
On obtient donc une recette après sélection des différents items et un clic. 


```{r}
#################### 1 - Recettes #####################################----------------

#1 - Création de la recette : on met toutes les variables dans un premier temps
#Voulez vous retirer des variables du modèle ? (liste des variables)
#Voulez-vous centrer réduire les variables ? (oui/non)

#Modèle avec toutes les variables
vins_rec1 <- 
  recipe(quality ~ ., data = train_data) 

#Modèle avec deux variables en moins
vins_rec2 <- 
  recipe(quality ~ ., data = train_data) %>% 
  step_rm(c(fixed.acidity,volatile.acidity))

#Modèle avec toutes les variables centrées réduites
vins_rec3 <- 
  recipe(quality ~ ., data = train_data) %>%
  step_normalize(all_numeric_predictors())
# %>% step_dummy(all_nominal_predictors()) : pour transformer les variables nominales en indicatrices
# %>% update_role(flight, time_hour, new_role = "ID") : pour retirer des variables du modèle
# %>%step_normalize(all_numeric_predictors()) #pour centrer réduire
# %>% step_zv() #pour enlever les variables avec une seules valeur
# %>% step_rm() #removes variables

##############         2 - Modèles      ########################-----------------
```


### Choix de l'algo

Paramètre algo : 
Une autre fenêtre avec le choix de l'algorithme : 
- la regression logistique
- l'arbre (hyparamètres par défaut)
- le KNN (hyparamètres par défaut)
- la forêt (hyparamètres par défaut)
On obtient un modèle (à voir si on optimise les hyper-paramètres)

```{r}
#2 - Choix de l'algorithme :

#2-1 la regression logistique
lr_mod <- 
  logistic_reg() %>% 
  set_engine("glm")


#2-2 la forêt aléatoire
rf_mod <- 
  rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")


#3-3 l'arbre de décision
tree_mod <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune() 
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
#Hyper-paramètres à tester
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5)
#Je teste 25 combinaisons d'hyper paramètres pour trouver le meilleur arbre

#3-4 la regression lasso
lasso_mod <- 
  logistic_reg(penalty = tune(), 
               mixture = 1) %>% 
  set_engine("glmnet")
#lasso grid : 30 hyper-paramètres à tester
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))

```


### Nom algo

On joint la recette et le modèle pour arriver à un workflow, qui est la 
variable globale de ce module qu'on va utiliser dans le sous-module suivant. 


```{r}
############# 3 - Workflows     ########################--------------

#3 - Création des workflows

#pour la logistique et la première recette
vins_wflow_lr1 <- 
  workflow() %>% 
  add_model(lr_mod) %>% #ajout de la regression logistique
  add_recipe(vins_rec1) #on garde toutes les variables

#pour la logistique et la deuxième recette
vins_wflow_lr2 <- 
  workflow() %>% 
  add_model(lr_mod) %>% #ajout de la regression logistique
  add_recipe(vins_rec2) #avec deux variables en moins


vins_wflow_rf <- 
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(vins_rec1)

vins_wflow_tree <- 
  workflow() %>% 
  add_model(tree_mod) %>% 
  add_recipe(vins_rec1)

vins_workflow_lasso <- 
  workflow() %>% 
  add_model(lasso_mod) %>% 
  add_recipe(vins_rec2)


```

Dans ce module, on affiche la base d'entraînement (qui peut être modifiée) et le modèle choisi + son nom.

## menuSubItem : entraînement

On récupère un workflow de l'étape précédente. 
On choisit si on fait une validation croisée (combien de folds) ?
Une validation croisée stratifiée ? 
ou alors une validation hold-out ?
ou une validation croisée leave-one-out ?

```{r}
#Mise en place d'une validation croisée
set.seed(345)
folds <- vfold_cv(train_data, v = 10)#paramétrage de la validation croisée 



############# 4 - Entraînement du modèle directement sur le workflow #######------

#Sans validation croisée, sans optimisation des paramètres

########### Sans la validation croisée #######
vins_fit_lr1 <- 
  vins_wflow_lr1 %>% 
  fit(data = train_data)

vins_fit_lr2 <- 
  vins_wflow_lr2 %>% 
  fit(data = train_data)

########### Avec validation croisée #######
vins_fit_lr1_vc <- 
  vins_wflow_lr1 %>% 
  fit(data = train_data) %>% 
  fit_resamples(folds)



print(vins_fit_lr1)
print(vins_fit_lr2)

vins_fit_lr1_vc %>% collect_metrics()

vins_fit_rf <- 
  vins_wflow_rf %>% 
  fit(data = train_data) %>% 
  fit_resamples(folds) #pour ajouter la validation croisée définie plus haut

#Avec validation croisée et optimisation des hyper-paramètres



vins_fit_tree <- 
  vins_wflow_tree %>% 
  tune_grid(
    resamples = folds,
    grid = tree_grid
  )



#5 - Visualisation du résultat (regression logistique et random forest)

#ne marche pas quand on met en place de la validation croisée
vins_fit %>% 
  extract_fit_parsnip() #%>% 
  tidy() #le tidy ne marche pas pour la forêt aléatoire

  #pour voir les résultats avec la validation croisée
collect_metrics(vins_fit_rs)
  
  
#6 - Prédiction sur la base de test
predict(vins_fit,test_data) #renvoie une base avec une colonne de résultats 
predict(vins_fit,test_data,type = "prob") #renvoie une base avec deux colonnes de proba
vins_aug <- augment(vins_fit, test_data) #renvoie une base avec aussi les probas 


#7 - analyse de la performance

#affichage de la courbe ROC
vins_aug %>% 
  roc_curve(truth = quality, .pred_bon) %>% 
  autoplot()

#Aire sous la courbe
vins_aug %>% 
  roc_auc(truth = quality, .pred_bon)

#Accuracy : pourcentage de biens classés
vins_aug %>% 
  accuracy(truth = quality, .pred_class)

#Spécificité
vins_aug %>% 
  specificity(truth = quality, .pred_class)

#Sensitivité
vins_aug %>% 
  sensitivity(truth = quality, .pred_class)


# Quel algorithme voulez-vous utilisez ? 
# 1 - Regression logistique ? 
# 2 - KNN ?
# 3 - Forêt aléatoire ?

# Quelle validation voulez vous utiliser sur le fichier d'entraînement ? 
# 1 - Validation normale ?
# 2 - Validation croisée ?
# 3 - Validation hold-out ?


```

A la fin de cette étape, on a choisi un modèle : on prend le meilleur au vu des résultats et on clique sur OK. 
c'est ce modèle qui sera utilisé pour la généralisation sur la phase de test. 

## menuSubItem : généralisation

En entrée, on a le modèle qui a été sélectionné.

On a sélectionné le meilleur modèle et on teste ses performances sur des données qu'il n'a jamais vu. 
On fait apparaître le tableau de truc + courve AUC + Accuracy (pour voir le taux de biens classés par exemple).

# menuItem 2 : Regression


