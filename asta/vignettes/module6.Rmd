---
title: "module6"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{module6}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r setup}
library(asta)
library(skimr)
library(tidymodels)
```

# menuItem 1 : les données

## menuSubItem 1 : Dictionnaire des variables

```{r}
glimpse(vins)
```


## menuSubitem 2 : Exploration

```{r}
skim(vins)
```

## menuItem 2 : Classification supervisée

## menuSubItem : preparation de la base

```{r}
#paramètres
part_training <- 3/4 #proportion du découpage aléatoire en training et test
var_strata <- "quality" #variable de stratification : souvent la variable target
nb_folds <-10 #nombre de classes pour la validation croisée

set.seed(123)
#Découpage en training et en test
data_split <- rsample::initial_split(vins, 
                                     strata = .data[[var_strata]],
                                     prop = part_training)

train_data <- training(data_split) #le fichier d'entraînement
test_data <- testing(data_split) #le fichier de test

#Mise en place d'une validation croisée
set.seed(345)
folds <- vfold_cv(train_data, v = 10)#paramétrage de la validation croisée 


#Apprentissage


#################### 1 - Recettes #####################################----------------

#1 - Création de la recette : on met toutes les variables dans un premier temps
#Voulez vous retirer des variables du modèle ? (liste des variables)
#Voulez-vous centrer réduire les variables ? (oui/non)
vins_rec1 <- 
  recipe(quality ~ ., data = train_data) 
# %>% step_dummy(all_nominal_predictors()) : pour transformer les variables nominales en indicatrices
# %>% update_role(flight, time_hour, new_role = "ID") : pour retirer des variables du modèle
# %>%step_normalize(all_numeric_predictors()) #pour centrer réduire
# %>% step_zv() #pour enlever les variables avec une seules valeur
# %>% step_rm() #removes variables

vins_rec2 <- 
  recipe(quality ~ ., data = train_data) %>% 
  step_normalize(all_numeric_predictors())
##############         2 - Modèles      ########################-----------------

#2 - Choix de l'algorithme :

#2-1 la regression logistique
lr_mod <- 
  logistic_reg() %>% 
  set_engine("glm")


#2-2 la forêt aléatoire
rf_mod <- 
  rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")


#3-3 l'arbre de décision
tree_mod <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune() 
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
#Hyper-paramètres à tester
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5)
#Je teste 25 combinaisons d'hyper paramètres pour trouver le meilleur arbre

#3-4 la regression lasso
lasso_mod <- 
  logistic_reg(penalty = tune(), 
               mixture = 1) %>% 
  set_engine("glmnet")
#lasso grid : 30 hyper-paramètres à tester
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))

############# 3 - Workflows     ########################--------------

#3 - Création des workflows

#pour la logistique et la première recette
vins_wflow_lr <- 
  workflow() %>% 
  add_model(lr_mod) %>% #ajout de la regression logistique
  add_recipe(vins_rec) #on garde toutes les variables


vins_wflow_rf <- 
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(vins_rec1)

vins_wflow_tree <- 
  workflow() %>% 
  add_model(tree_mod) %>% 
  add_recipe(vins_rec1)

vins_workflow_lasso <- 
  workflow() %>% 
  add_model(lasso_mod) %>% 
  add_recipe(vins_rec2)

############# 4 - Entraînement du modèle directement sur le workflow #######------

#Sans validation croiése, sans optimisation des paramètres

###########Sans la validation croisée#######
vins_fit_lr <- 
  vins_wflow_lr %>% 
  fit(data = train_data) 

#Avec validation croisée, sans optimisation des hyper-paramètres

#Avec la validation croisée
vins_fit_rf <- 
  vins_wflow_rf %>% 
  fit(data = train_data) %>% 
  fit_resamples(folds) #pour ajouter la validation croisée définie plus haut

#Avec validation croisée et optimisation des hyper-paramètres

vins_fit_tree <- 
  vins_wflow_tree %>% 
  tune_grid(
    resamples = folds,
    grid = tree_grid
  )



#5 - Visualisation du résultat (regression logistique et random forest)

#ne marche pas quand on met en place de la validation croisée
vins_fit %>% 
  extract_fit_parsnip() #%>% 
  tidy() #le tidy ne marche pas pour la forêt aléatoire

  #pour voir les résultats avec la validation croisée
collect_metrics(vins_fit_rs)
  
  
#6 - Prédiction sur la base de test
predict(vins_fit,test_data) #renvoie une base avec une colonne de résultats 
predict(vins_fit,test_data,type = "prob") #renvoie une base avec deux colonnes de proba
vins_aug <- augment(vins_fit, test_data) #renvoie une base avec aussi les probas 


#7 - analyse de la performance

#affichage de la courbe ROC
vins_aug %>% 
  roc_curve(truth = quality, .pred_bon) %>% 
  autoplot()

#Aire sous la courbe
vins_aug %>% 
  roc_auc(truth = quality, .pred_bon)

#Accuracy : pourcentage de biens classés
vins_aug %>% 
  accuracy(truth = quality, .pred_class)

#Spécificité
vins_aug %>% 
  specificity(truth = quality, .pred_class)

#Sensitivité
vins_aug %>% 
  sensitivity(truth = quality, .pred_class)


# Quel algorithme voulez-vous utilisez ? 
# 1 - Regression logistique ? 
# 2 - KNN ?
# 3 - Forêt aléatoire ?

# Quelle validation voulez vous utiliser sur le fichier d'entraînement ? 
# 1 - Validation normale ?
# 2 - Validation croisée ?
# 3 - Validation hold-out ?


```


## menuItem 3 : Regression


